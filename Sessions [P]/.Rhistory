5+7
x < 3+4
x < 3+4
x <- 3+4
x <- 5+7
figures_folder <- "/Users/lotterhos/Documents/GitHub/CnGV/results/Simulation_10.10.2020/PhenotypePlots/"
simIDs <- c(10621, 15539, 1843, 2715, 3443, 3508, 8313, 9034)
x
x-3
y <- x-3
y
z <- c(1.1., 9, 3.14)
z <- c(1.1, 9, 3.14)
exit()
library(swirl)
swirl()
?c
z
demo_lesson()
c(z,555,z)
z*2+100
my_sqrt <- sqrt(z) - 1
my_sqrt <- sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1, 2, 3, 4) + c(0, 10, 100)
z*2+1000
my_div
swirl()
install_course("Exploratory_Data_Analysis")
swirl()
head(pollution)
0
0
0
0
bye()
swirl()
5+7
bye()
setwd("~/Dropbox/S15_SampleCode")
## Climate data. note that all precipitation variables have been log-transformed
A <- read.csv("X.NAnaec8.ref.csv") # 1971-2000 climate normals for all land cells of the DEM
B <- read.csv("X.NAnaec8.proj_GlobalMean_RCP45_2085.csv") # 2071-2100 climate normals (RCP4.5 ensemble mean projection) for all land cells of the DEM.
C <- read.csv("X.stn_detrended.csv") # ICV proxy data. Linearly detrended 1951-1990 annual time series at selected CRU TS3.23 climate stations. these time series are used as proxies for local interannual climate variability ("ICV proxies")
C.id <- read.csv("A.stn_detrended.csv")[,1] # the id number for each ICV proxy.
proxy <- read.csv("grid4nn_NAnaec8.csv")[,1]  # the ICV proxy used for each grid cell.
head(A)
nrow(A)
nrow(B)
nrow(C)
head(C)
hist(C[,1])
hist(A[,1])
hist(C[,1])
head(proxy)
proxy
## subsample the analog pool to reduce processing time
subsample <- read.csv("subsample.NAnaec8.csv")[,1]
subsample
# Principal component truncation rule
trunc.SDs <- 0.1 #truncation
#initiate the data frame to store the projected sigma dissimilarity of best analogs for each grid cell.
NN.sigma <- rep(NA,length(proxy))
NN.sigma
sort(unique(proxy))
j=1
## Select data relevant to ICV proxy j
Bj <- B[which(proxy==j),]   # select locations for which ICV proxy j is the closest ICV proxy.
Cj <- C[which(C.id==j),] # reference period (1951-1990) ICV at ICV proxy j
Bj
Cj
## Step 1: express climate data as standardized anomalies of reference period (1951-1990) ICV at ICV proxy j.
Cj.sd <- apply(Cj,2,sd, na.rm=T)  #standard deviation of 1951-1990 interannual variability in each climate variable, ignoring missing years
Cj.sd
hist(C[,1])
hist(A[,1])
Yj.prime
X.prime
A
whichStation
j
## Select data relevant to ICV proxy j
Bj <- B[which(proxy==j),]   # set of data from station j
# select locations for which ICV proxy j is the closest ICV proxy.
Cj <- C[which(C.id==j),]    # reference period ICV at ICV proxy j
## Step 1: express climate data as standardized anomalies of reference period
#  ICV at ICV proxy j.
Cj.sd <- apply(Cj,2,sd, na.rm=T)  #standard deviation of interannual variability in each climate variable, ignoring missing years
#standard deviation of variability in each climate
# variable, ignoring missing years
A.prime <- sweep(A[,-1],MARGIN=2,Cj.sd[-1],`/`) #standardize the reference ICV
# a <- matrix(c(1,2,3,4,5,6), nrow=2)
# sweep(a, MARGIN =2, STATS=c(2,3,4)) # subtracts STATs from each column
# sweep(a, MARGIN =2, STATS=c(2,3,4), FUN=`/`) # divides each column by STATS
Bj.prime <- sweep(Bj[,-1],MARGIN=2,Cj.sd[-1],`/`) #standardize the analog pool
Cj.prime <- sweep(Cj[,-1],MARGIN=2,Cj.sd[-1],`/`) #standardize the projected future conditions of grid cells represented by ICV proxy j
Cj.prime
head(Cj.prime)
head(A.prime)
colnames(Cj.prime) <- colnames(A.prime)
Cj.prime[!is.na(apply(Cj.prime,1,mean)),]
## Step 2: Extract the principal components (PCs) of the reference period ICV
# and project all data onto these PCs
PCA <- prcomp(Cj.prime[!is.na(apply(Cj.prime,1,mean)),])
# Principal components analysis. The !is.na(apply(...)) term is there
# simply to select all years with complete observations in all variables.
PCA$rotation
plot(PCA$rotation[,1], PCA$rotation[,2], xlim=c(-0.6, 0.1))
text(PCA$rotation[1:4,1], PCA$rotation[1:4,2], rownames(PCA$rotation)[1:4])
plot(PCA$rotation[,1], PCA$rotation[,3], xlim=c(-0.6, 0.1))
text(PCA$rotation[1:4,1], PCA$rotation[1:4,3], rownames(PCA$rotation)[1:4])
(PCs <- max(c(which(unlist(summary(PCA)[1])>trunc.SDs),1)))
PCs
# find the number of PCs to retain using the PC truncation
# rule of eigenvector stdev > the truncation threshold
X <- as.data.frame(predict(PCA,A.prime))   # X is new baseline
# project the analog pool onto the PCs
head(X)
nrow(X)
# find the number of PCs to retain using the PC truncation
# rule of eigenvector stdev > the truncation threshold
X <- as.data.frame(predict(PCA,A.prime))   # X is new baseline
# project the analog pool onto the PCs
head(X)
Yj <- as.data.frame(predict(PCA,Bj.prime))
Zj <- as.data.frame(predict(PCA,Cj.prime))
Zj
nrow(Zj)
nrow(Yj)
## Step 3a: express PC scores as standardized anomalies of reference interannual variability
Zj.sd <- apply(Zj,2,sd, na.rm=T)
#standard deviation of 1951-1990 interannual variability in each principal component, ignoring missing years
#Zj.sd
X.prime <- sweep(X,MARGIN=2,Zj.sd,`/`) # standardized baseline
#standardize the analog pool
#head(X.prime)
Yj.prime <- sweep(Yj,MARGIN=2,Zj.sd,`/`)
Zj.prime <- sweep(Zj, MARGIN=2, Zj.sd,`/`)
#plot(X.prime[,1], X.prime[,2], xlim=c(-60, 20)) # analog
#points(Zj.prime[,1], Zj.prime[,2], pch=19, col=rgb(1,0,0, 0.5)) # reference ICV
#points(Yj.prime[,1], Yj.prime[,2], pch=19, col=rgb(0,1,0)) # future conditions
#standardize the projected conditions
#Yj.prime
## Step 3b: find the sigma dissimilarity of each projected condition with
# its best analog (Euclidean nearest neighbour) in the observed analog pool.
#X.prime <- X.prime[complete.cases(X.prime),] # standardized baseline
nnd <- get.knnx(data=X.prime[,1:PCs],
query=Yj.prime[,1:PCs],
k=1,algorithm="brute")
library(FNN)
#plot(X.prime[,1], X.prime[,2], xlim=c(-60, 20)) # analog
#points(Zj.prime[,1], Zj.prime[,2], pch=19, col=rgb(1,0,0, 0.5)) # reference ICV
#points(Yj.prime[,1], Yj.prime[,2], pch=19, col=rgb(0,1,0)) # future conditions
#standardize the projected conditions
#Yj.prime
## Step 3b: find the sigma dissimilarity of each projected condition with
# its best analog (Euclidean nearest neighbour) in the observed analog pool.
#X.prime <- X.prime[complete.cases(X.prime),] # standardized baseline
nnd <- get.knnx(data=X.prime[,1:PCs],
query=Yj.prime[,1:PCs],
k=1,algorithm="brute")
nnd
NN.dist <- as.vector(nnd[[2]])
NN.dist
# Euclidean nearest neighbour distance in the z-standardized PCs of
# interannual climatic variability, i.e. the Mahalanobian nearest neighbour.
NN.chi <- pchi(NN.dist,PCs, rel.tol=.Machine$double.eps^0.8)
library(adehabitatLT)
# Euclidean nearest neighbour distance in the z-standardized PCs of
# interannual climatic variability, i.e. the Mahalanobian nearest neighbour.
NN.chi <- pchi(NN.dist,PCs, rel.tol=.Machine$double.eps^0.8)
NN.chi
# percentile of the nearest neighbour
# increase the precision with 'rel.tol' #(default is ^0.5) to help with rounding error issues
# distance on the chi distribution with degrees of freedom
# equaling the dimensionality of the distance measurement (PCs)
if(NN.chi>=(1-1e-16)){NN.chi=1-1e-16}
NN.chi
# sometimes with rounding error the NN.chi is printed as 1 but so close to 1 that
# small changes in the decimal place equal large changes in sigma.
# Also, if NN.chi equals 1 exactly than NN.sigma is infinite
# this slight transformation gives the largest possible value of NN.sigma
NN.sigma <- qchi(NN.chi,1)
NN.sigma
# values of the chi percentiles on a standard half-normal distribution (chi distribution with one degree of freedom)
if(NN.dist>9){NN.sigma <- qchi(1-1e-16,1) }
complete.cases(X.prime)
plot(X[,1], X[,2], xlim=c(-60, 20)) # analog
points(Zj[,1], Zj[,2], pch=19, col=rgb(1,0,0, 0.5)) # reference ICV
points(Yj[,1], Yj[,2], pch=19, col=rgb(0,1,0)) # future conditions
proxy
B$No
C.id
proxy
plot(X.prime[,1], X.prime[,2], xlim=c(-60, 20)) # analog
points(Zj.prime[,1], Zj.prime[,2], pch=19, col=rgb(1,0,0, 0.5)) # reference ICV
points(Yj.prime[,1], Yj.prime[,2], pch=19, col=rgb(0,1,0)) # future conditions
head(Bj)
install.packages("jsonlite", repos="http://cran.r-project.org")
install.packages("httr")
#Use the libraries
library(jsonlite) #https://cran.r-project.org/web/packages/jsonlite/
library(httr)
#Fill in the AphiaID you need
AphiaID <- 127160
#Build the URL to get the data from
url <- sprintf("https://www.marinespecies.org/traits/rest/AphiaClassificationByAphiaID/%d", AphiaID);
url
#Get the actual data from the URL
classificationTree <- fromJSON(url)
source("https://raw.githubusercontent.com/jorgeassis/marineforestsDB/master/sourceMe.R")
dataset <- extractDataset("brownAlgae",pruned=TRUE)
nrow(dataset)
dataset <- extractDataset("brownAlgae",pruned=FALSE)
nrow(dataset)
unique(dataset$basisOfRecord)
unqiue(dataset$sourceType)
unique(dataset$sourceType)
dataset <- dataset[dataset$sourceType == "Literature",]
dataset$sourceType <- FALSE
dataset1 <- extractDataset("brownAlgae",pruned=FALSE)
dataset2 <- extractDataset("seagrasses",pruned=FALSE)
dataset <- rbind(dataset1,dataset2)
dataset <- dataset[dataset$sourceType == "Literature",]
dataset$sourceType <- FALSE
nrow(dataset)
write.csv(database,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests Literature/dataBase.csv",row.names = FALSE)
write.csv(dataset,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests Literature/dataBase.csv",row.names = FALSE)
dataset1 <- extractDataset("brownAlgae",pruned=FALSE)
dataset2 <- extractDataset("seagrasses",pruned=FALSE)
dataset <- rbind(dataset1,dataset2)
unique(dataset$sourceType)
dataset <- dataset[dataset$sourceType %in% c("Literature","Herbarium"),]
unique(dataset$sourceType)
unique(dataset$sourceType)[1]
unique(dataset$sourceType)[2]
dataset$sourceType <- FALSE
nrow(dataset)
write.csv(dataset,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests Literature/dataBase.csv",row.names = FALSE)
min(dataset$year,na.rm=T)
min(as.numeric(as.character(dataset$year)),na.rm=T)
max(as.numeric(as.character(dataset$year)),na.rm=T)
dataset$license <- "https://creativecommons.org/licenses/by-nc/4.0/legalcode"
write.csv(dataset,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests Literature/dataBase.csv",row.names = FALSE)
source("https://raw.githubusercontent.com/jorgeassis/marineforestsDB/master/sourceMe.R")
dataset1 <- extractDataset("brownAlgae",pruned=FALSE)
dataset2 <- extractDataset("seagrasses",pruned=FALSE)
dataset <- rbind(dataset1,dataset2)
unique(dataset$sourceType)
dataset <- dataset[dataset$sourceType %in% c("Literature","Herbarium"),]
dataset$sourceType <- FALSE
nrow(dataset)
dataset$license <- "https://creativecommons.org/licenses/by-nc/4.0/legalcode"
write.csv(dataset,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests/dataBase.csv",row.names = FALSE)
unique(dataset$license )
write.csv(dataset,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests/dataBase.csv",row.names = FALSE)
min(as.numeric(as.character(dataset$year)),na.rm=T)
max(as.numeric(as.character(dataset$year)),na.rm=T)
min(dataset$year,na.rm=T)
unqiue(dataset$occurrenceID)
unique(dataset$occurrenceID)
sum(dupplicated(dataset$occurrenceID))
sum(duplicated(dataset$occurrenceID))
duplicated(dataset$occurrenceID)
dataset$occurrenceID <- paste0("MF-",1:nrow(dataset))
sum(duplicated(dataset$occurrenceID))
names(dataset)
dataset$id <- 1:nrow(dataset)
names(dataset)
unique(dataset$bibliographicCitation)
class(dataset$occurrenceID)
names(dataset)
c=1
names(dataset[,c])
names(dataset)[c]
names(dataset)
columnsAsNumeric <- c("year","month","day","decimalLatitude","decimalLongitude","minimumDepthInMeters","maximumDepthInMeters","coordinateUncertaintyInMeters","depthAccuracy")
c=1
gsub(";",",",dataset[,c])
dataset[,c]
names(dataset)
names(dataset)[c]
as.numeric(as.character(dataset[,c]))
names(dataset)[c]
names(dataset)
c=71
as.numeric(as.character(dataset[,c]))
dataset[,c]
as.numeric(as.character(dataset[,c]))
dataset1 <- extractDataset("brownAlgae",pruned=FALSE)
dataset2 <- extractDataset("seagrasses",pruned=FALSE)
dataset <- rbind(dataset1,dataset2)
dataset <- dataset[dataset$sourceType %in% c("Literature","Herbarium"),]
dataset$sourceType <- FALSE
dataset$individualCount <- NULL
dataset$license <- "https://creativecommons.org/licenses/by-nc/4.0/legalcode"
dataset$occurrenceID <- paste0("MF-",1:nrow(dataset))
dataset$id <- 1:nrow(dataset)
names(dataset)
dataset$coordinatePrecision <- NULL
columnsAsNumeric <- c("year","month","day","decimalLatitude","decimalLongitude","minimumDepthInMeters","maximumDepthInMeters","coordinateUncertaintyInMeters","depthAccuracy")
for(c in 1:ncol(dataset) ) {
dataset[,c] <- gsub(";",",",dataset[,c])
if( names(dataset)[c] %in% columnsAsNumeric ) {
dataset[,c] <- as.numeric(as.character(dataset[,c]))
}
if( ! names(dataset)[c] %in% columnsAsNumeric ) {
dataset[,c] <- as.character(dataset[,c])
}
}
which(dataset$minimumDepthInMeters > dataset$maximumDepthInMeters)
unique(dataset$minimumDepthInMeters )
class(dataset$minimumDepthInMeters)
unique(dataset$maximumDepthInMeters)
write.csv(dataset,file="/Users/jorgeassis/Dropbox/Data/GBIF data catalogs/Marine Forests/dataBase.csv",row.names = FALSE)
min(dataset$year,na.rm=T)
max(dataset$year,na.rm=T)
dataset$country <- NULL
a = 3
b=6
a + b
x <- c(1,2,3,4,5,6)
y <- c(2,4,6,8,10,12)
plot(x,y)
a = 9
g= 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
r= 673639399937937494738400000003333373936383893974758954848373636527384850606095857744646647474
a *b -g
456 / 6
maiorque100 <- function(x) {
if( x > 100) { print("É maior")}
if( x < 100) { print("É menor")}
}
maiorque100(2)
maiorque100(200)
maiorque100(345 )
maiorque100(100)
maiorque100 <- function(x) {
if( x > 100) { print("É maior")}
if( x < 100) { print("É menor")}
if( x == 100) { print("É 100!!")}
}
maiorque100(100)
maiorque100 <- function(x) {
if( x > 100) { print("É maior")}
if( x < 100) { print("É menor")}
if( x == 100) { print("És burro!!")}
}
maiorque100(100)
setwd("~/Dropbox/Tutoring/Classes & Courses/MarAfrica, modelling the distribution of biodiversity and climate change/Git/courseMarAfrica/Sessions [P]")
install.packages("kableExtra")
install.packages("sp", dependencies = TRUE)
seagrass <- shapefile('Data/vectorShapefiles/seagrass/cymodoceaNodosa.shp')
library(raster)
data1 <- "Data/vectorShapefiles/seagrass/cymodoceaNodosa.shp"
data2 <- "Data/vectorShapefiles/globalLandmass/world.shp"
records <- shapefile(data1)
world <- shapefile(data2)
plot(world)
plot(records)
plot(world)
plot(records, add=TRUE,col="red")
library(raster)
data <- "Data/vectorShapefiles/globalLandmass/world.shp"
world <- shapefile(data)
# Crop with extent
regionAzores <- extent(-36, -18, 34, 42)
azores <- crop(world,regionAzores)
plot(azores)
library(raster)
SST <- raster("Data/rasterLayers/Climate/Present/OceanTemperature Surface Pred Mean.tif")
plot(SST, main ="Sea Surface Temperatures")
plot(azores, axes=TRUE)
library(raster)
SST <- raster("Data/rasterLayers/Climate/Present/OceanTemperature Surface Pred Mean.tif")
plot(SST, main ="Sea Surface Temperatures")
library(raster)
presentSST <- raster("Data/rasterLayers/Climate/Present/OceanTemperature Surface Pred Mean.tif")
futureSST <- raster("Data/rasterLayers/Climate/RCP85/OceanTemperature Surface Pred Mean.tif")
differenceSST <- futureSST - presentSST
plot(differenceSST, main="Global warming" )
plot(differenceSST, main="Global warming" , axes=T)
library(raster)
presentSST <- raster("Data/rasterLayers/Climate/Present/OceanTemperature Surface Pred Mean.tif")
futureSST <- raster("Data/rasterLayers/Climate/RCP85/OceanTemperature Surface Pred Mean.tif")
differenceSST <- futureSST - presentSST
westAfricaExtent <- extent(-30, 22, -37.5, 36)
differenceSSTWAfrica <- crop(differenceSST,westAfricaExtent)
plot(differenceSSTWAfrica, main="West Africa warming" )
data1 <- "Data/rasterLayers/BathymetryDepthMean.tif"
data2 <- "Data/dataBases/Paramuricea_clavata.csv"
bathymetry <- raster(data1)
occurrences <- read.csv(data2,sep=";")
colnames(occurrences)
depthsUsed <- extract(bathymetry,occurrences[,c("Lon","Lat")])
hist(depthsUsed,breaks=100)
depthsUsed
devtools::install_github("cfree14/freeR")
library(freeR)
devtools::install_github("cfree14/freeR")
library(freeR)
install.packages("FishLife")
devtools::install_github("cfree14/freeR")
devtools::install_github("cfree14/freeR")
library(freeR)
devtools::install_github("james-thorson/FishLife")
devtools::install_github("cfree14/freeR")
library( FishLife )
library(freeR)
lh_data <- fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
library(dplyr)
lh_data <- fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
install.packages("rlang")
library(dplyr)
lh_data <- fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
library(dplyr)
install.packages("dplyr")
library(dplyr)
library(dplyr)
library( FishLife )
library(freeR)
lh_data <- fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
lh_data <- freeR::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
?fishbase
lh_data <- freeR::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
detach(rfishbase)
detach(rfishbase)
detach("rfishbase")
?detach
?library
detach("rfishbase")
?fishbase
fishbase()
fishbase
lh_data <- freeR::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
lh_data <- fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
rfishbase::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
freeR::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
fishbase
fishbase()
lh_data <- fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
lh_data <- freeR::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
library(dplyr)
lh_data <- freeR::fishbase(dataset="species", species="Corallium rubrum", level="species", cleaned=T)
remotes::install_github("ropensci/rfishbase")
library(rfishbase)
sealife <- load_taxa(server="sealifebase")
dim(sealife)
sealife2 <- fb_tbl("species", "sealifebase")
sealife2
dim(sealife2)
head(sealife2)
names(sealife2)
View(sealife2)
sealife2$DepthRangeShallow
sealife2 <- as.data.frame(fb_tbl("species", "sealifebase"))
dim(sealife2)
head(sealife2)
fb_tables()
sealife3 <- as.data.frame(fb_tbl("faoareas", "sealifebase"))
head(sealife3)
dim(sealife3)
tail(sealife3)
sealife2[sealife2$Species == "Corallium rubrum",]
sealife2[sealife2$Genus == "Corallium",]
sealife3[sealife3$SpecCode == "42663",]
sealife3[which(sealife3$SpecCode == "42663"),]
fb_tables()
sealife4 <- as.data.frame(fb_tbl("faoarref", "sealifebase"))
dim(sealife4)
sealife4
sealife4 <- as.data.frame(fb_tbl("biblio", "sealifebase"))
dim(sealife4)
head(sealife4)
sealife4[which(sealife4$SpecCode == "42663"),]
sealife3[which(sealife3$SpecCode == "42663"),]
sealife4[which(sealife4$autoctr == "681447"),]
sealife3[which(sealife3$SpecCode == "42663"),]
sealife4[which(sealife4$SpecCode == "42663"),]
sealife5 <- as.data.frame(fb_tbl("estimatedepth", "sealifebase"))
sealife6 <- as.data.frame(fb_tbl("faoaquacult", "sealifebase"))
head(sealife5)
dim(sealife5)
head(sealife6)
dim(sealife6)
fb_tables()
sealife5[which(sealife4$SpecCode == "42663"),]
sealife5[which(sealife5$SpecCode == "42663"),]
head(sealife5)
sealife6 <- as.data.frame(fb_tbl("aquamaps", "sealifebase"))
head(sealife6)
sealife7 <- as.data.frame(fb_tbl("biblio2", "sealifebase"))
head(sealife7)
sealife8 <- as.data.frame(fb_tbl("diet", "sealifebase"))
head(sealife8)
sealife9 <- as.data.frame(fb_tbl("diet_items", "sealifebase"))
head(sealife9)
dim(sealife9)
sealife10 <- as.data.frame(fb_tbl("ecosystem", "sealifebase"))
head(sealife10)
sealife11 <- as.data.frame(fb_tbl("ecology", "sealifebase"))
head(sealife11)
sealife11[which(sealife11$SpecCode == "42663"),]
dim(sealife11)
sealife12 <- as.data.frame(fb_tbl("estimate", "sealifebase"))
head(sealife12)
dim(sealife12)
sealife12[which(sealife12$SpecCode == "42663"),]
